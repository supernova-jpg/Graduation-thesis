{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x198d0dd8330>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "    batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "    batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  i =0 \n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    i+=1\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    print(i)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      #torch.save(network.state_dict(), '/results/model.pth')\n",
    "      #torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "image_list = []\n",
    "\n",
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      image_list.append(data)\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      prediction.append(pred)\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-6c2218f37724>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.038379\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 0.894982\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.978856\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.701902\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.791902\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.786420\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.884543\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.031465\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.808686\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.667236\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.714515\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.737810\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.995120\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.629469\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.631113\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.651742\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.546281\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.705519\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.904779\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.448053\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.608349\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.831928\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.721670\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.473825\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.582158\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.562290\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.839631\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.527638\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.560760\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.703210\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.561157\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.599918\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.560513\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.953701\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.456496\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.624607\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.578254\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.545884\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.663826\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.573194\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.662056\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.378923\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.557871\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.436289\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.613797\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.771284\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.510400\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.440527\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.377424\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.459615\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.470584\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.589483\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.609400\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.421533\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.579184\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.522838\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.375497\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.638299\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.486333\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.359967\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.530604\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.629642\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.718481\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.562016\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.505782\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.768193\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.654805\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.488474\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.439685\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.384031\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.400192\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.571867\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.343068\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.516847\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.249648\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.599241\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.342861\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.639089\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.470712\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.384664\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.465540\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.602343\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.386986\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.281909\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.372853\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.488490\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.585206\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.203106\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.483974\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.388274\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.299074\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.711623\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.442335\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.466551\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1695, Accuracy: 9474/10000 (95%)\n",
      "\n",
      "1\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.329538\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.139184\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.234835\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.393693\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.518279\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.381914\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.307677\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.357738\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.404461\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.229989\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.519791\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.437441\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.299902\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.291843\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.316126\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.359493\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.356440\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.431467\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.317971\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.298037\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.538683\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.174697\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.371252\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.339899\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.618859\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.543937\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.271203\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.459361\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.263155\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.385878\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.397093\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.317436\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.347420\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.463007\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.456201\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.211029\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.550516\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.430702\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.371535\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.180456\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.464077\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.387790\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.397469\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.655881\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.278697\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.363075\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.275845\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.208411\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.316224\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.200299\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.291470\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.404576\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.305338\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.380231\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.279814\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.630067\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.674520\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.253168\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.307943\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.438165\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.395681\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.373944\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.409249\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.180791\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.449552\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.338502\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.380230\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.413848\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.223721\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.158831\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.536420\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.530720\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.404380\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.367066\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.435784\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.568234\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.358703\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.188896\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.383542\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.196877\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.241425\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.318403\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.278185\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.400964\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.287607\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.173012\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.263662\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.309139\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.570416\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.269112\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.274761\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.290732\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.300757\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.138076\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "\n",
      "Test set: Avg. loss: 0.1231, Accuracy: 9598/10000 (96%)\n",
      "\n",
      "1\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.177345\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.366852\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.414108\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.377954\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.236639\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.321611\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.195623\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.363125\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.169927\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.344516\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.286830\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.280172\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.422698\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.500549\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.244163\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.296650\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.313316\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.601047\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.127060\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.326905\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.412059\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.527775\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.386321\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.233326\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.340201\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.269666\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.263565\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.203730\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.248413\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.226507\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.189253\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.281930\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.203863\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.256958\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.231512\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.307181\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.286550\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.241962\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.221277\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.348473\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.541505\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.272420\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.372350\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.305498\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.338745\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.258342\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.201793\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.231622\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.290289\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.318115\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.545188\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.234106\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.325983\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.637393\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.215571\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.325507\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.290327\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.192627\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.199143\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.255932\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.215453\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.263752\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.268501\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.290584\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.169654\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.536442\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.403862\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.347733\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.261317\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.200583\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.279135\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.367826\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.225356\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.071925\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.118114\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.345425\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.234902\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.226804\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.144148\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.314219\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.114966\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.254430\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.318222\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.214987\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.259581\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.201387\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.173680\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.200152\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.155291\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.337917\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.119437\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.179480\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.248161\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.308300\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "\n",
      "Test set: Avg. loss: 0.0979, Accuracy: 9698/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(9):\n",
    "  plt.subplot(3,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(image_list[9][i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    prediction[9][i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
